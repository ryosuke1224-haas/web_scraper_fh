{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryosu\\OneDrive\\デスクトップ\\Peek\\hh-scraper\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\ryosu\\OneDrive\\デスクトップ\\Peek\\hh-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\ryosu\\anaconda3\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: configparser in c:\\users\\ryosu\\anaconda3\\lib\\site-packages (from webdriver-manager) (5.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ryosu\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.22.0)\n",
      "Requirement already satisfied: crayons in c:\\users\\ryosu\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryosu\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2020.6.20)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\ryosu\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ryosu\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\ryosu\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryosu\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager) (0.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\ryosu\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from urllib.parse import urljoin\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import postal code\n",
    "postalcode=pd.read_excel('Zipcodes_for_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill O for zipcode\n",
    "zip_5=[]\n",
    "for i in postalcode['Zip']:\n",
    "    zip_5.append('{0:05d}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - There is no [win32] chromedriver for browser 87.0.4280 in cache\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/87.0.4280.88/chromedriver_win32.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\ryosu\\.wdm\\drivers\\chromedriver\\win32\\87.0.4280.88]\n"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Chrome(ChromeDriverManager().install())\n",
    "links=[]\n",
    "baseurl='https://www.findahaunt.com/'\n",
    "for i in zip_5:\n",
    "    url = 'https://www.findahaunt.com/'\n",
    "    browser.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        search = browser.find_element_by_id(\"searchbox\")\n",
    "        search.clear()\n",
    "        search.send_keys(i)\n",
    "        element=browser.find_element_by_id(\"submit\")\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        page_source = browser.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        operators_name = soup.find_all(\"a\",class_=\"prohaunt list_name\")\n",
    "        for i in operators_name:\n",
    "            #print(urljoin(baseurl,i.get(\"href\")))\n",
    "            links.append(urljoin(baseurl,i.get(\"href\")))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_file=pd.DataFrame(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_file.to_csv('links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_file=pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_file=links_file.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_file=links_file.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "adresses=[]\n",
    "webs=[]\n",
    "phones=[]\n",
    "try:\n",
    "    for i in links_file[\"0\"]:\n",
    "        res = requests.get(i)\n",
    "        individualpage = BeautifulSoup(res.text, 'lxml')\n",
    "        name = individualpage.find(\"article\",class_=\"content-listing\").find(\"h1\").text\n",
    "        names.append(name)\n",
    "        try:\n",
    "            adress=individualpage.find(\"article\",class_=\"content-listing\").find('p').find(\"a\").text\n",
    "            adresses.append(adress)\n",
    "        except:\n",
    "            adresses.append('cannot find')\n",
    "        \n",
    "        try:\n",
    "            web=individualpage.find(\"a\",class_=\"hauntsite\").get(\"href\")\n",
    "            web=web.replace('?utm_source=FindAHaunt.com&utm_medium=website&utm_campaign=HauntedHouseMedia','')\n",
    "            webs.append(web)\n",
    "        \n",
    "        except:\n",
    "            webs.append('cannot find')\n",
    "        \n",
    "        try:\n",
    "            phone=individualpage.find_all(text=re.compile(r'\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d'))\n",
    "            phones.append(phone)\n",
    "        except:\n",
    "            phones.append('cannot find')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\n",
    "    \"name\":names,\n",
    "    \"adress\":adresses,\n",
    "    \"website\":webs,\n",
    "    \"phone\":phones\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output_findahaunt.csv')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
